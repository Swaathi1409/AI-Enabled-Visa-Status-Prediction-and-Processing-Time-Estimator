{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Milestone 3 - Predictive Modeling\n",
        "\n"
      ],
      "metadata": {
        "id": "nED8HekkGIxd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Importing libraries\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "import joblib"
      ],
      "metadata": {
        "id": "GlCOJDSfGPEL"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading feature engineered dataset created on Milestone 2\n",
        "df = pd.read_csv(\"visa_dataset_feature_engineered.csv\")\n",
        "\n",
        "# Define target and features\n",
        "y = df[\"Processing Time (Days)\"]\n",
        "X = df.drop(columns=[\"Processing Time (Days)\", \"Visa Status\"])\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")"
      ],
      "metadata": {
        "id": "iTxT0PnuGVa8"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading preprocessor from Milestone 1\n",
        "preprocessor = joblib.load(\"visa_preprocessor.pkl\")\n",
        "\n",
        "# Transform data\n",
        "X_train_trans = preprocessor.transform(X_train)\n",
        "X_test_trans = preprocessor.transform(X_test)"
      ],
      "metadata": {
        "id": "AMyx1_tRGoLO"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Baseline Model\n",
        "models = {\n",
        "    \"Linear Regression\": LinearRegression(),\n",
        "    \"Random Forest\": RandomForestRegressor(random_state=42),\n",
        "    \"Gradient Boosting\": GradientBoostingRegressor(random_state=42)\n",
        "}"
      ],
      "metadata": {
        "id": "OmG63qMaHfM7"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = {}\n",
        "def evaluate_model(name, model, X_train, y_train, X_test, y_test):\n",
        "    model.fit(X_train, y_train)\n",
        "    preds = model.predict(X_test)\n",
        "\n",
        "    mae = mean_absolute_error(y_test, preds)\n",
        "    rmse = np.sqrt(mean_squared_error(y_test, preds))\n",
        "    r2 = r2_score(y_test, preds)\n",
        "\n",
        "    results[name] = [mae, rmse, r2]\n",
        "    print(f\"\\n{name}\")\n",
        "    print(\"MAE :\", mae)\n",
        "    print(\"RMSE:\", rmse)\n",
        "    print(\"R² Score:\", r2)"
      ],
      "metadata": {
        "id": "aHQICmMjHsu7"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train and evaluate baseline models\n",
        "for name, model in models.items():\n",
        "    evaluate_model(name, model, X_train_trans, y_train, X_test_trans, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qE7B3YvVHy6g",
        "outputId": "9eca8ec6-29d2-4d98-bbcb-2c9c0c0ddd15"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Linear Regression\n",
            "MAE : 4.242649988501375\n",
            "RMSE: 6.312244619290182\n",
            "R² Score: 0.9233622847108139\n",
            "\n",
            "Random Forest\n",
            "MAE : 4.382071\n",
            "RMSE: 6.429956412760509\n",
            "R² Score: 0.9204773277610148\n",
            "\n",
            "Gradient Boosting\n",
            "MAE : 4.362385629867506\n",
            "RMSE: 6.372905871784863\n",
            "R² Score: 0.9218822159082087\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Selection Summary\n",
        "\n",
        "Based on the evaluation metrics, **Linear Regression is the best-performing model**.\n",
        "\n",
        "#### Performance Comparison\n",
        "| Model | MAE (↓) | RMSE (↓) | R² (↑) |\n",
        "|-------|---------|-----------|---------|\n",
        "| **Linear Regression** | **4.24** | **6.31** | **0.92336** |\n",
        "| Gradient Boosting | 4.36 | 6.37 | 0.92188 |\n",
        "| Random Forest | 4.38 | 6.43 | 0.92048 |\n",
        "\n",
        "#### Why Linear Regression Wins\n",
        "- Lowest **MAE** → most accurate on average.  \n",
        "- Lowest **RMSE** → fewer large errors.  \n",
        "- Highest **R²** → explains the most variance in processing time.  \n",
        "- Features created during preprocessing show **strong linear relationships**, making linear regression ideal.  \n",
        "- Ensemble models slightly overfit, while linear regression generalizes better.\n",
        "\n",
        "#### Conclusion\n",
        "**Linear Regression is selected as the final model for deployment** due to its superior accuracy, stability, and interpretability.\n"
      ],
      "metadata": {
        "id": "MDvH9TCMIa9c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tuning RandomForest using RandomizedSearchCV\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "VeXL69ULdbPU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "rf = RandomForestRegressor()\n",
        "\n",
        "param_dist = {\n",
        "    'n_estimators': [50, 100, 150],\n",
        "    'max_depth': [5, 10, 15],\n",
        "    'min_samples_split': [2, 5],\n",
        "    'min_samples_leaf': [1, 2],\n",
        "    'max_features': ['sqrt']\n",
        "}\n",
        "\n",
        "search = RandomizedSearchCV(\n",
        "    estimator=rf,\n",
        "    param_distributions=param_dist,\n",
        "    n_iter=6,\n",
        "    cv=2,\n",
        "    scoring='neg_mean_absolute_error',\n",
        "    n_jobs=-1,\n",
        "    verbose=2\n",
        ")\n",
        "\n",
        "# USE TRANSFORMED DATA\n",
        "search.fit(X_train_trans, y_train)\n",
        "\n",
        "print(\"Best Parameters:\", search.best_params_)\n",
        "print(\"Best MAE:\", -search.best_score_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cXsQUnVvMAwt",
        "outputId": "5cdc11ba-39ca-4a52-d312-b8ff5ae8bb97"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 2 folds for each of 6 candidates, totalling 12 fits\n",
            "Best Parameters: {'n_estimators': 150, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': 15}\n",
            "Best MAE: 4.8799297534944035\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tuning GradientBoost using RandomizedSearchCV\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "joUYjX9qdork"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "import numpy as np\n",
        "\n",
        "# Use transformed data\n",
        "X_train_gb = X_train_trans\n",
        "X_test_gb = X_test_trans\n",
        "\n",
        "gb = GradientBoostingRegressor(random_state=42)\n",
        "\n",
        "param_dist_gb = {\n",
        "    'n_estimators': [50, 100, 150],\n",
        "    'learning_rate': [0.01, 0.05, 0.1],\n",
        "    'max_depth': [2, 3, 4],\n",
        "    'min_samples_split': [2, 5],\n",
        "    'min_samples_leaf': [1, 2]\n",
        "}\n",
        "\n",
        "gb_search = RandomizedSearchCV(\n",
        "    estimator=gb,\n",
        "    param_distributions=param_dist_gb,\n",
        "    n_iter=8,\n",
        "    cv=2,\n",
        "    scoring='neg_mean_absolute_error',\n",
        "    n_jobs=-1,\n",
        "    verbose=2,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "gb_search.fit(X_train_gb, y_train)\n",
        "\n",
        "print(\"Best Gradient Boosting Parameters:\", gb_search.best_params_)\n",
        "print(\"Best MAE:\", -gb_search.best_score_)\n",
        "\n",
        "# Evaluate on test set\n",
        "gb_best = gb_search.best_estimator_\n",
        "gb_preds = gb_best.predict(X_test_gb)\n",
        "\n",
        "test_mae = mean_absolute_error(y_test, gb_preds)\n",
        "test_rmse = np.sqrt(np.mean((y_test - gb_preds)**2))\n",
        "test_r2 = gb_best.score(X_test_gb, y_test)\n",
        "\n",
        "print(\"\\n===== Tuned Gradient Boosting Test Performance =====\")\n",
        "print(\"MAE :\", test_mae)\n",
        "print(\"RMSE:\", test_rmse)\n",
        "print(\"R² Score:\", test_r2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LrB_cv5Kbr3H",
        "outputId": "d3507e98-9358-4351-c14d-bbc333a1b601"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 2 folds for each of 8 candidates, totalling 16 fits\n",
            "Best Gradient Boosting Parameters: {'n_estimators': 150, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_depth': 2, 'learning_rate': 0.1}\n",
            "Best MAE: 4.421893233679947\n",
            "\n",
            "===== Tuned Gradient Boosting Test Performance =====\n",
            "MAE : 4.393291260650672\n",
            "RMSE: 6.389805366296463\n",
            "R² Score: 0.9214673654584936\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based on both baseline and hyperparameter-tuned results, Linear Regression is the best-performing model for the visa processing time prediction task.\n",
        "\n",
        "\n",
        "• It achieves the lowest MAE (4.24), lowest RMSE (6.31), and the highest R² score (0.9233).  \n",
        "• Random Forest performance worsened after tuning (MAE ≈ 4.85), indicating that tree-based methods are not well-suited to this dataset.  \n",
        "• Tuned Gradient Boosting improved but still did not outperform Linear Regression (MAE ≈ 4.39, R² ≈ 0.9214).  \n",
        "\n",
        "\n",
        "These results show that the dataset relationships are mostly linear, and adding model complexity does not improve performance.  \n",
        "\n",
        "\n",
        "Thus, **Linear Regression is selected as the final model for deployment.**\n"
      ],
      "metadata": {
        "id": "i2DXGhqLd7DZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Select best model\n",
        "best_model_name = min(results, key=results.get)\n",
        "best_model = models[best_model_name]\n",
        "\n",
        "print(\"\\nBest Model Based on MAE:\", best_model_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VmgErIgh3SwW",
        "outputId": "976ecbe7-aea9-466c-fb8b-60628449a268"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Best Model Based on MAE: Linear Regression\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "joblib.dump(best_model, \"best_regression_model.pkl\")\n",
        "print(\"\\nSaved: best_regression_model.pkl\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m4cRw2EE3bn2",
        "outputId": "3b737bcf-791f-4602-c4af-eb8f5dfa733c"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Saved: best_regression_model.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Predicting in the test set"
      ],
      "metadata": {
        "id": "qA_B6jYj56ZM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Take 1 sample from test set\n",
        "sample = X_test.iloc[[0]]\n",
        "sample_trans = preprocessor.transform(sample)\n",
        "\n",
        "prediction = best_model.predict(sample_trans)[0]\n",
        "prediction = max(0, prediction)\n",
        "\n",
        "print(\"\\nSample Prediction (Days):\", prediction)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gC9yc4ln3hRC",
        "outputId": "d86359dd-156f-42f4-aba1-a03bedebd8f7"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Sample Prediction (Days): 16.80235368849185\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Predicting by giving manual input"
      ],
      "metadata": {
        "id": "EHG9-utxAZ_p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# HELPER FUNCTIONS\n",
        "\n",
        "def compute_date_features(date_str):\n",
        "    d = pd.to_datetime(date_str)\n",
        "    return d.month, d.weekday(), d.isocalendar().week\n",
        "\n",
        "def get_season_index(season):\n",
        "    mapping = {\"Low\": 1, \"Mid\": 2, \"Off-Peak\": 3, \"Peak\": 4}\n",
        "    return mapping.get(season, 2)    # default mid\n",
        "\n",
        "def get_country_avg(country):\n",
        "    return df[df[\"Applicant Nationality\"] == country][\"Processing Time (Days)\"].mean()\n",
        "\n",
        "def get_visa_avg(vtype):\n",
        "    return df[df[\"Visa Type\"] == vtype][\"Processing Time (Days)\"].mean()\n",
        "\n",
        "def get_center_load(center):\n",
        "    return len(df[df[\"Processing Center\"] == center])"
      ],
      "metadata": {
        "id": "Tcz3BToXAQS-"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prediction function\n",
        "def predict_processing_time(\n",
        "    application_date,\n",
        "    decision_date,\n",
        "    visa_type,\n",
        "    nationality,\n",
        "    center,\n",
        "    season,\n",
        "    complexity,\n",
        "    completeness,\n",
        "    expedited\n",
        "):\n",
        "\n",
        "    # Generate date-related features\n",
        "    app_month, app_day, app_week = compute_date_features(application_date)\n",
        "    dec_month, dec_day, dec_week = compute_date_features(decision_date)\n",
        "\n",
        "    # Generate engineered features\n",
        "    season_idx = get_season_index(season)\n",
        "    country_avg = get_country_avg(nationality)\n",
        "    visa_avg = get_visa_avg(visa_type)\n",
        "    center_load = get_center_load(center)\n",
        "\n",
        "    # Build final row for prediction\n",
        "    input_df = pd.DataFrame([{\n",
        "        \"Application Date\": application_date,\n",
        "        \"Decision Date\": decision_date,\n",
        "        \"Visa Type\": visa_type,\n",
        "        \"Applicant Nationality\": nationality,\n",
        "        \"Processing Center\": center,\n",
        "        \"Season\": season,\n",
        "        \"Application Complexity\": complexity,\n",
        "        \"Document Completeness\": completeness,\n",
        "        \"Expedited Request\": expedited,\n",
        "        \"Application_Month\": app_month,\n",
        "        \"Application_DayOfWeek\": app_day,\n",
        "        \"Application_WeekOfYear\": app_week,\n",
        "        \"Decision_Month\": dec_month,\n",
        "        \"Decision_DayOfWeek\": dec_day,\n",
        "        \"Decision_WeekOfYear\": dec_week,\n",
        "        \"Season_Index\": season_idx,\n",
        "        \"Country_Avg_Processing\": country_avg,\n",
        "        \"VisaType_Avg_Processing\": visa_avg,\n",
        "        \"Center_Load\": center_load\n",
        "    }])\n",
        "\n",
        "    # Transform with preprocessor\n",
        "    transformed = preprocessor.transform(input_df)\n",
        "\n",
        "    # Predict\n",
        "    prediction = best_model.predict(transformed)[0]\n",
        "    return max(0, prediction)"
      ],
      "metadata": {
        "id": "FTmCGTI4_0vs"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Sample Prediction\n",
        "result = predict_processing_time(\n",
        "    application_date=\"2024-01-21\",\n",
        "    decision_date=\"2024-03-10\",\n",
        "    visa_type=\"Business\",\n",
        "    nationality=\"India\",\n",
        "    center=\"Delhi\",\n",
        "    season=\"Peak\",\n",
        "    complexity=0,\n",
        "    completeness=1,\n",
        "    expedited=0\n",
        ")\n",
        "\n",
        "print(\"Predicted Processing Time (Days):\", result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vhiTzTfw__1c",
        "outputId": "858b4928-4a64-40b0-f795-b25a1def2e2b"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Processing Time (Days): 44.10037460740214\n"
          ]
        }
      ]
    }
  ]
}